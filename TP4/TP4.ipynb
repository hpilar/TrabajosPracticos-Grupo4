{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bfb891c",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 4 - Regularización aplicada a la EPH \n",
    "\n",
    "## Gil Deza, Hüppi Lo Prete, Walker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a153ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29cef715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>$(\"div.input\").hide()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cab104646594281a93c7f450d8dbb72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, description='Show code')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>$(\"div.input\").show()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utilizamos el código de la clase tutorial para crear un botón para ocultar el código \n",
    "#Fuente: https://stackoverflow.com/questions/27934885/how-to-hide-code-from-cells-in-ipython-notebook-visualized-with-nbviewer\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "javascript_functions = {False: \"hide()\", True: \"show()\"}\n",
    "button_descriptions  = {False: \"Show code\", True: \"Hide code\"}\n",
    "\n",
    "\n",
    "def toggle_code(state):\n",
    "\n",
    "    \"\"\"\n",
    "    Toggles the JavaScript show()/hide() function on the div.input element.\n",
    "    \"\"\"\n",
    "\n",
    "    output_string = \"<script>$(\\\"div.input\\\").{}</script>\"\n",
    "    output_args   = (javascript_functions[state],)\n",
    "    output        = output_string.format(*output_args)\n",
    "\n",
    "    display(HTML(output))\n",
    "\n",
    "\n",
    "def button_action(value):\n",
    "\n",
    "    \"\"\"\n",
    "    Calls the toggle_code function and updates the button description.\n",
    "    \"\"\"\n",
    "\n",
    "    state = value.new\n",
    "\n",
    "    toggle_code(state)\n",
    "\n",
    "    value.owner.description = button_descriptions[state]\n",
    "\n",
    "\n",
    "state = False\n",
    "toggle_code(state)\n",
    "\n",
    "button = widgets.ToggleButton(state, description = button_descriptions[state])\n",
    "button.observe(button_action, \"value\")\n",
    "\n",
    "display(button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc2f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos un comando para que no salten los warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5451f0",
   "metadata": {},
   "source": [
    "### Parte I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c032579",
   "metadata": {},
   "source": [
    "Para esta parte recuperaremos lo realizado en los TPs anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16386cc8",
   "metadata": {},
   "source": [
    "#### 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531227cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos la base de hogar \n",
    "df_ba=pd.read_excel(\"usu_hogar_T122.xls\")\n",
    "# Armamos un nuevo df solo con las observaciones de Buenos Aires y Gran Buenos Aires\n",
    "df_ba = df_ba.loc[df_ba['AGLOMERADO'].isin([32, 33])]\n",
    "# Abrimos la tabla de usuarios \n",
    "df_usu=pd.read_excel(\"usu_individual_T122.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be144507",
   "metadata": {},
   "source": [
    "#### 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62a70c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODUSU</th>\n",
       "      <th>ANO4_x</th>\n",
       "      <th>TRIMESTRE_x</th>\n",
       "      <th>NRO_HOGAR</th>\n",
       "      <th>REALIZADA</th>\n",
       "      <th>REGION_x</th>\n",
       "      <th>MAS_500_x</th>\n",
       "      <th>AGLOMERADO_x</th>\n",
       "      <th>PONDERA_x</th>\n",
       "      <th>IV1</th>\n",
       "      <th>...</th>\n",
       "      <th>PDECIFR_y</th>\n",
       "      <th>ADECIFR_y</th>\n",
       "      <th>IPCF_y</th>\n",
       "      <th>DECCFR_y</th>\n",
       "      <th>IDECCFR_y</th>\n",
       "      <th>RDECCFR_y</th>\n",
       "      <th>GDECCFR_y</th>\n",
       "      <th>PDECCFR_y</th>\n",
       "      <th>ADECCFR_y</th>\n",
       "      <th>PONDIH_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TQRMNOQSYHMOTOCDEIJAH00698520</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>4625</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TQRMNOPSSHKKMMCDEIIAD00780111</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>32</td>\n",
       "      <td>803</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>103750.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TQRMNOPSSHKKMMCDEIIAD00780111</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>32</td>\n",
       "      <td>803</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>103750.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TQRMNORSUHLMNPCDEIIAD00718267</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>32</td>\n",
       "      <td>2785</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>4073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TQRMNORSUHLMNPCDEIIAD00718267</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>32</td>\n",
       "      <td>2785</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>4073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>TQRMNOPQSHMMKPCDEIJAH00780780</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>2607</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>24500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>TQRMNOPWPHMLLLCDEIJAH00780781</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>2325</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>4528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>TQRMNOPWPHMLLLCDEIJAH00780781</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>2325</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>4528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>TQRMNORUVHLLKQCDEIJAH00718720</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>2102</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>TQRMNORUVHLLKQCDEIJAH00718720</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>33</td>\n",
       "      <td>2102</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6706 rows × 263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             CODUSU  ANO4_x  TRIMESTRE_x  NRO_HOGAR  \\\n",
       "0     TQRMNOQSYHMOTOCDEIJAH00698520    2022            1          1   \n",
       "1     TQRMNOPSSHKKMMCDEIIAD00780111    2022            1          1   \n",
       "2     TQRMNOPSSHKKMMCDEIIAD00780111    2022            1          1   \n",
       "3     TQRMNORSUHLMNPCDEIIAD00718267    2022            1          1   \n",
       "4     TQRMNORSUHLMNPCDEIIAD00718267    2022            1          1   \n",
       "...                             ...     ...          ...        ...   \n",
       "6701  TQRMNOPQSHMMKPCDEIJAH00780780    2022            1          1   \n",
       "6702  TQRMNOPWPHMLLLCDEIJAH00780781    2022            1          1   \n",
       "6703  TQRMNOPWPHMLLLCDEIJAH00780781    2022            1          1   \n",
       "6704  TQRMNORUVHLLKQCDEIJAH00718720    2022            1          1   \n",
       "6705  TQRMNORUVHLLKQCDEIJAH00718720    2022            1          1   \n",
       "\n",
       "      REALIZADA  REGION_x MAS_500_x  AGLOMERADO_x  PONDERA_x  IV1  ...  \\\n",
       "0             1         1         S            33       4625    2  ...   \n",
       "1             1         1         S            32        803    1  ...   \n",
       "2             1         1         S            32        803    1  ...   \n",
       "3             1         1         S            32       2785    2  ...   \n",
       "4             1         1         S            32       2785    2  ...   \n",
       "...         ...       ...       ...           ...        ...  ...  ...   \n",
       "6701          1         1         S            33       2607    1  ...   \n",
       "6702          1         1         S            33       2325    1  ...   \n",
       "6703          1         1         S            33       2325    1  ...   \n",
       "6704          1         1         S            33       2102    1  ...   \n",
       "6705          1         1         S            33       2102    1  ...   \n",
       "\n",
       "     PDECIFR_y  ADECIFR_y    IPCF_y DECCFR_y  IDECCFR_y  RDECCFR_y  GDECCFR_y  \\\n",
       "0          NaN          0       0.0        0        NaN          0        0.0   \n",
       "1          NaN          8  103750.0       10        NaN         10       10.0   \n",
       "2          NaN          8  103750.0       10        NaN         10       10.0   \n",
       "3          NaN         10  145000.0       10        NaN         10       10.0   \n",
       "4          NaN         10  145000.0       10        NaN         10       10.0   \n",
       "...        ...        ...       ...      ...        ...        ...        ...   \n",
       "6701       NaN          6   24500.0        4        NaN          3        3.0   \n",
       "6702       NaN          4   34000.0        5        NaN          5        5.0   \n",
       "6703       NaN          4   34000.0        5        NaN          5        5.0   \n",
       "6704       NaN         12       0.0       12        NaN         12       12.0   \n",
       "6705       NaN         12       0.0       12        NaN         12       12.0   \n",
       "\n",
       "      PDECCFR_y ADECCFR_y  PONDIH_y  \n",
       "0           NaN         0      4410  \n",
       "1           NaN         8      1440  \n",
       "2           NaN         8      1440  \n",
       "3           NaN         9      4073  \n",
       "4           NaN         9      4073  \n",
       "...         ...       ...       ...  \n",
       "6701        NaN         4      5084  \n",
       "6702        NaN         6      4528  \n",
       "6703        NaN         6      4528  \n",
       "6704        NaN        12         0  \n",
       "6705        NaN        12         0  \n",
       "\n",
       "[6706 rows x 263 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ba_unido = pd.merge(df_ba, df_usu, on=(\"CODUSU\",\"NRO_HOGAR\"), how=\"inner\", validate=\"one_to_many\")\n",
    "df_ba_unido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7855ef23",
   "metadata": {},
   "source": [
    "Eliminamos todas las columnas duplicadas luego del merge, dado que se encontraban en ambas bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "156cfe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba_unido.drop(columns=(df_ba_unido.filter(regex='_y')), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6184a471",
   "metadata": {},
   "source": [
    "#### 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce138ebe",
   "metadata": {},
   "source": [
    "Para la limpieza a conciencia de la base de datos eliminaremos, en primer lugar, aquellas variables que contengan más del 50% de sus observaciones con valores faltantes. Esto se debe a que consideramos que serán variables que no aportarán valor informativo suficiente a nuestros modelos predictivos, sino que traerán aparejados problemas para su estimación. Como nuestra base contiene en total 6706 observaciones, realizamos el corte de 50% en 3372 observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5a94bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos la base de los datos nulos\n",
    "# Eliminamos columnas que tienen más del 50% de observaciones vacías \n",
    "df_ba_unido_limpio = df_ba_unido.dropna(axis=1, thresh= len(df_ba_unido)/2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3135432a",
   "metadata": {},
   "source": [
    "En segundo lugar, eliminamos los outliers de nuestras variables, dado que también pueden generar problemas en nuestras predicciones. Consideramos outliers todas las observaciones que están en el cuantil 1% superior e inferior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74aaf87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos outliers \n",
    "for column in df_ba_unido_limpio.columns[1:]:\n",
    "    if df_ba_unido_limpio[column].dtype== \"str\":\n",
    "        continue\n",
    "    elif df_ba_unido_limpio[column].dtype== \"object\":\n",
    "        continue\n",
    "    else:\n",
    "        q_low = df_ba_unido_limpio[column].quantile(q = 0.01)\n",
    "        q_hi = df_ba_unido_limpio[column].quantile(q = 0.99)\n",
    "        f_filtrada = df_ba_unido_limpio[(df_ba_unido_limpio[column]<q_hi) & (df_ba_unido_limpio[column]>q_low)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a65acc",
   "metadata": {},
   "source": [
    "<span style='background :yellow' > Creo que tendría más sentido que el condicional sea únicamente ver si es numero en vez de ver que no es un no-numero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583cd97",
   "metadata": {},
   "source": [
    "En tercer lugar, chequeamos cuál es el contenido de las variables que nos generarían problemas al no ser numéricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37091b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAS_500_x es una variable object\n",
      "CH05 es una variable object\n"
     ]
    }
   ],
   "source": [
    "for column in f_filtrada.columns[1:]:\n",
    "    if f_filtrada[column].dtype == \"int64\":\n",
    "        continue\n",
    "    elif f_filtrada[column].dtype == \"float64\":\n",
    "        continue\n",
    "    else:\n",
    "        print(column, \"es una variable\", f_filtrada[column].dtype)\n",
    "#print(list(f_filtrada.CH05))\n",
    "#print(list(f_filtrada.MAS_500_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8548ae",
   "metadata": {},
   "source": [
    "\n",
    "Observamos que CH05 contiene la fecha de nacimiento de los individuos (con lo cual podríamos borrarla, dado que tenemos su edad en la base también)\n",
    "\n",
    "MAS_500_x contienen una letra que indica el tamaño del aglomerado. Al habernos quedado con las observaciones de BsAs y Gran BsAs, todas tienen una \"S\".\n",
    "\n",
    "Debido a esto, consideramos que podemos deshacernos de tales variables sin mayores problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b24a63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_filtrada.drop(columns=\"CH05\", inplace=True)\n",
    "f_filtrada.drop(columns=\"MAS_500_x\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed248ba4",
   "metadata": {},
   "source": [
    "A continuación, chequearemos y eliminaremos todas las observaciones que tengan valores negativos sin sentido, por ejemplo, para el ingreso o la edad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "929dbc42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CODUSU, ANO4_x, TRIMESTRE_x, NRO_HOGAR, REALIZADA, REGION_x, AGLOMERADO_x, PONDERA_x, IV1, IV2, IV3, IV4, IV5, IV6, IV7, IV8, IV9, IV10, IV11, IV12_1, IV12_2, IV12_3, II1, II2, II3, II3_1, II4_1, II4_2, II4_3, II5, II5_1, II6, II6_1, II7, II8, II9, V1, V2, V21, V22, V3, V4, V5, V6, V7, V8, V9, V10, V11, V12, V13, V14, V15, V16, V17, V18, V19_A, V19_B, IX_TOT, IX_MEN10, IX_MAYEQ10, ITF_x, DECIFR_x, RDECIFR_x, GDECIFR_x, ADECIFR_x, IPCF_x, DECCFR_x, RDECCFR_x, GDECCFR_x, ADECCFR_x, PONDIH_x, VII1_1, VII1_2, VII2_1, VII2_2, VII2_3, VII2_4, COMPONENTE, H15, CH03, CH04, CH06, CH07, CH08, CH09, CH10, CH11, CH12, CH13, CH15, CH16, NIVEL_ED, ESTADO, CAT_OCUP, CAT_INAC, PP02C1, PP02C2, PP02C3, PP02C4, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 133 columns]\n",
      "Empty DataFrame\n",
      "Columns: [CODUSU, ANO4_x, TRIMESTRE_x, NRO_HOGAR, REALIZADA, REGION_x, AGLOMERADO_x, PONDERA_x, IV1, IV2, IV3, IV4, IV5, IV6, IV7, IV8, IV9, IV10, IV11, IV12_1, IV12_2, IV12_3, II1, II2, II3, II3_1, II4_1, II4_2, II4_3, II5, II5_1, II6, II6_1, II7, II8, II9, V1, V2, V21, V22, V3, V4, V5, V6, V7, V8, V9, V10, V11, V12, V13, V14, V15, V16, V17, V18, V19_A, V19_B, IX_TOT, IX_MEN10, IX_MAYEQ10, ITF_x, DECIFR_x, RDECIFR_x, GDECIFR_x, ADECIFR_x, IPCF_x, DECCFR_x, RDECCFR_x, GDECCFR_x, ADECCFR_x, PONDIH_x, VII1_1, VII1_2, VII2_1, VII2_2, VII2_3, VII2_4, COMPONENTE, H15, CH03, CH04, CH06, CH07, CH08, CH09, CH10, CH11, CH12, CH13, CH15, CH16, NIVEL_ED, ESTADO, CAT_OCUP, CAT_INAC, PP02C1, PP02C2, PP02C3, PP02C4, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 133 columns]\n",
      "                             CODUSU  ANO4_x  TRIMESTRE_x  NRO_HOGAR  \\\n",
      "6     TQRMNORUPHMLRMCDEIJAH00698717    2022            1          1   \n",
      "7     TQRMNORUPHMLRMCDEIJAH00698717    2022            1          1   \n",
      "8     TQRMNORUPHMLRMCDEIJAH00698717    2022            1          1   \n",
      "9     TQRMNOTUYHMMKNCDEIJAH00698671    2022            1          1   \n",
      "10    TQRMNOTUYHMMKNCDEIJAH00698671    2022            1          1   \n",
      "...                             ...     ...          ...        ...   \n",
      "6648  TQRMNOQVWHKMLNCDEIJAH00780811    2022            1          1   \n",
      "6649  TQRMNOQVWHKMLNCDEIJAH00780811    2022            1          1   \n",
      "6666  TQRMNORTYHJMORCDEIJAH00780813    2022            1          1   \n",
      "6667  TQRMNORTYHJMORCDEIJAH00780813    2022            1          1   \n",
      "6704  TQRMNORUVHLLKQCDEIJAH00718720    2022            1          1   \n",
      "\n",
      "      REALIZADA  REGION_x  AGLOMERADO_x  PONDERA_x  IV1  IV2  ...  V5_M  V8_M  \\\n",
      "6             1         1            33       1698    1    4  ...     0     0   \n",
      "7             1         1            33       1698    1    4  ...     0     0   \n",
      "8             1         1            33       1698    1    4  ...     0     0   \n",
      "9             1         1            33       3764    1    4  ...     0     0   \n",
      "10            1         1            33       3764    1    4  ...     0     0   \n",
      "...         ...       ...           ...        ...  ...  ...  ...   ...   ...   \n",
      "6648          1         1            33       2926    1    2  ...     0     0   \n",
      "6649          1         1            33       2926    1    2  ...     0     0   \n",
      "6666          1         1            33       2194    1    2  ...     0     0   \n",
      "6667          1         1            33       2194    1    2  ...     0     0   \n",
      "6704          1         1            33       2102    1    2  ...     0     0   \n",
      "\n",
      "      V9_M  V10_M  V11_M  V12_M  V18_M  V19_AM  V21_M   T_VI  \n",
      "6        0      0      0      0      0       0      0      0  \n",
      "7        0      0      0      0      0       0      0      0  \n",
      "8        0      0      0      0      0       0      0      0  \n",
      "9        0      0      0      0      0       0      0      0  \n",
      "10       0      0      0      0      0       0      0      0  \n",
      "...    ...    ...    ...    ...    ...     ...    ...    ...  \n",
      "6648     0      0      0      0      0       0      0  29000  \n",
      "6649     0      0      0      0      0       0      0      0  \n",
      "6666     0      0      0      0      0       0      0      0  \n",
      "6667     0      0      0      0      0       0      0      0  \n",
      "6704     0      0      0      0      0       0      0      0  \n",
      "\n",
      "[901 rows x 133 columns]\n",
      "                             CODUSU  ANO4_x  TRIMESTRE_x  NRO_HOGAR  \\\n",
      "6     TQRMNORUPHMLRMCDEIJAH00698717    2022            1          1   \n",
      "7     TQRMNORUPHMLRMCDEIJAH00698717    2022            1          1   \n",
      "8     TQRMNORUPHMLRMCDEIJAH00698717    2022            1          1   \n",
      "9     TQRMNOTUYHMMKNCDEIJAH00698671    2022            1          1   \n",
      "10    TQRMNOTUYHMMKNCDEIJAH00698671    2022            1          1   \n",
      "...                             ...     ...          ...        ...   \n",
      "6648  TQRMNOQVWHKMLNCDEIJAH00780811    2022            1          1   \n",
      "6649  TQRMNOQVWHKMLNCDEIJAH00780811    2022            1          1   \n",
      "6666  TQRMNORTYHJMORCDEIJAH00780813    2022            1          1   \n",
      "6667  TQRMNORTYHJMORCDEIJAH00780813    2022            1          1   \n",
      "6704  TQRMNORUVHLLKQCDEIJAH00718720    2022            1          1   \n",
      "\n",
      "      REALIZADA  REGION_x  AGLOMERADO_x  PONDERA_x  IV1  IV2  ...  V5_M  V8_M  \\\n",
      "6             1         1            33       1698    1    4  ...     0     0   \n",
      "7             1         1            33       1698    1    4  ...     0     0   \n",
      "8             1         1            33       1698    1    4  ...     0     0   \n",
      "9             1         1            33       3764    1    4  ...     0     0   \n",
      "10            1         1            33       3764    1    4  ...     0     0   \n",
      "...         ...       ...           ...        ...  ...  ...  ...   ...   ...   \n",
      "6648          1         1            33       2926    1    2  ...     0     0   \n",
      "6649          1         1            33       2926    1    2  ...     0     0   \n",
      "6666          1         1            33       2194    1    2  ...     0     0   \n",
      "6667          1         1            33       2194    1    2  ...     0     0   \n",
      "6704          1         1            33       2102    1    2  ...     0     0   \n",
      "\n",
      "      V9_M  V10_M  V11_M  V12_M  V18_M  V19_AM  V21_M   T_VI  \n",
      "6        0      0      0      0      0       0      0      0  \n",
      "7        0      0      0      0      0       0      0      0  \n",
      "8        0      0      0      0      0       0      0      0  \n",
      "9        0      0      0      0      0       0      0      0  \n",
      "10       0      0      0      0      0       0      0      0  \n",
      "...    ...    ...    ...    ...    ...     ...    ...    ...  \n",
      "6648     0      0      0      0      0       0      0  29000  \n",
      "6649     0      0      0      0      0       0      0      0  \n",
      "6666     0      0      0      0      0       0      0      0  \n",
      "6667     0      0      0      0      0       0      0      0  \n",
      "6704     0      0      0      0      0       0      0      0  \n",
      "\n",
      "[938 rows x 133 columns]\n",
      "                             CODUSU  ANO4_x  TRIMESTRE_x  NRO_HOGAR  \\\n",
      "97    TQRMNOSUXHLLTRCDEIJAH00718966    2022            1          1   \n",
      "180   TQRMNOQQWHLNNPCDEIJAH00719115    2022            1          1   \n",
      "183   TQRMNOPPWHJKLNCDEIJAH00719425    2022            1          1   \n",
      "474   TQRMNORYYHMOMOCDEIIAD00780105    2022            1          1   \n",
      "495   TQRMNOUTSHMOLRCDEIJAH00703950    2022            1          1   \n",
      "507   TQRMNOPPQHLNKTCDEIIAD00780107    2022            1          1   \n",
      "730   TQRMNORWRHKNNOCDEIJAH00780914    2022            1          1   \n",
      "915   TQRMNORPXHMMLSCDEIJAH00780187    2022            1          1   \n",
      "918   TQRMNOPYRHKOOLCDEIJAH00780188    2022            1          1   \n",
      "1052  TQRMNOQWQHLLROCDEIJAH00780208    2022            1          1   \n",
      "1171  TQRMNOQRVHKMKQCDEIJAH00780113    2022            1          1   \n",
      "1280  TQRMNOQXQHKMOQCDEIJAH00780116    2022            1          1   \n",
      "1527  TQRMNOURQHKOKOCDEIIAD00779758    2022            1          1   \n",
      "1694  TQRMNOSYTHMMPPCDEIJAH00702450    2022            1          1   \n",
      "1734  TQRMNORWPHMKKOCDEIJAH00703495    2022            1          2   \n",
      "1761  TQRMNOQXSHJMOMCDEIIAD00718628    2022            1          1   \n",
      "1779  TQRMNOQQWHMOKNCDEIJAH00780299    2022            1          1   \n",
      "1809  TQRMNOTXWHKMNQCDEIJAH00780321    2022            1          1   \n",
      "1972  TQRMNORYSHMMPQCDEIJAH00780313    2022            1          1   \n",
      "2029  TQRMNOQVTHLMQNCDEIJAH00719541    2022            1          1   \n",
      "2077  TQRMNOQVTHJMLPCDEIJAH00698167    2022            1          1   \n",
      "2151  TQRMNOQVPHMLNUCDEIIAD00699685    2022            1          1   \n",
      "2189  TQRMNOQRPHKKPQCDEIJAH00780277    2022            1          1   \n",
      "2190  TQRMNOQRPHKKPQCDEIJAH00780277    2022            1          1   \n",
      "2201  TQRMNOQXQHJLNMCDEIJAH00702707    2022            1          1   \n",
      "2245  TQRMNOPSWHMNPNCDEIJAH00703912    2022            1          1   \n",
      "2347  TQRMNOSSPHLOLSCDEIJAH00718822    2022            1          1   \n",
      "2377  TQRMNOQURHKOPMCDEIJAH00780286    2022            1          1   \n",
      "2727  TQRMNOSQQHMNNRCDEIJAH00780384    2022            1          1   \n",
      "2788  TQRMNOPUSHLMLTCDEIJAH00719260    2022            1          1   \n",
      "2798  TQRMNOQTUHJLPLCDEIJAH00780397    2022            1          1   \n",
      "2839  TQRMNOQXVHJMRLCDEIJAH00719480    2022            1          1   \n",
      "3081  TQRMNOQTVHJOPSCDEIJAH00780376    2022            1          1   \n",
      "3170  TQRMNOQVUHLKLPCDEIJAH00780349    2022            1          1   \n",
      "3265  TQRMNORWSHJMRMCDEIJAH00719482    2022            1          1   \n",
      "3301  TQRMNOTYUHKMLRCDEIIAD00779864    2022            1          1   \n",
      "3391  TQRMNOUVPHKMOOCDEIJAH00780342    2022            1          1   \n",
      "3510  TQRMNOUVVHLNLLCDEIIAD00779921    2022            1          1   \n",
      "3537  TQRMNOTPTHKKKRCDEIIAD00779928    2022            1          1   \n",
      "3724  TQRMNOSQQHJKTMCDEIJAH00780492    2022            1          1   \n",
      "3883  TQRMNOPSVHLNMQCDEIJAH00719196    2022            1          1   \n",
      "3984  TQRMNOPYQHJLMUCDEIIAD00718613    2022            1          1   \n",
      "3988  TQRMNORTRHJLMUCDEIIAD00718614    2022            1          1   \n",
      "4104  TQRMNOPUYHMKMTCDEIIAD00779953    2022            1          1   \n",
      "4376  TQRMNORVUHKOLSCDEIJAH00780578    2022            1          1   \n",
      "4482  TQRMNOPUVHJMMUCDEIJAH00700996    2022            1          1   \n",
      "4840  TQRMNOTPWHLKQSCDEIJAH00718701    2022            1          1   \n",
      "5205  TQRMNORWYHLNRMCDEIJAH00719242    2022            1          1   \n",
      "5287  TQRMNOPSYHMNQUCDEIJAH00701453    2022            1          1   \n",
      "5301  TQRMNOPXQHJMMNCDEIJAH00718918    2022            1          1   \n",
      "5576  TQRMNOPVRHMMOPCDEIIAD00698236    2022            1          2   \n",
      "5590  TQRMNOVQSHKMLOCDEIIAD00780009    2022            1          1   \n",
      "5621  TQRMNOSRSHKMKQCDEIJAH00780650    2022            1          1   \n",
      "5728  TQRMNOPPQHJMNRCDEIJAH00693035    2022            1          1   \n",
      "5930  TQRMNORPPHKNRUCDEIJAH00780763    2022            1          1   \n",
      "6046  TQRMNOQYSHKNKOCDEIJAH00780716    2022            1          1   \n",
      "6357  TQRMNOPUSHLKQLCDEIJAH00718844    2022            1          1   \n",
      "\n",
      "      REALIZADA  REGION_x  AGLOMERADO_x  PONDERA_x  IV1  IV2  ...  V5_M  V8_M  \\\n",
      "97            1         1            33       3525    1    3  ...     0     0   \n",
      "180           1         1            33        135    1    3  ...     0     0   \n",
      "183           1         1            33       1122    3    1  ...     0     0   \n",
      "474           1         1            32       4073    2    4  ...     0     0   \n",
      "495           1         1            33       2674    1    1  ...     0     0   \n",
      "507           1         1            32       4628    2    2  ...     0     0   \n",
      "730           1         1            33        571    1    2  ...     0     0   \n",
      "915           1         1            33       1112    2    3  ...     0     0   \n",
      "918           1         1            33       5318    1    3  ...     0     0   \n",
      "1052          1         1            33       3990    1    3  ...     0     0   \n",
      "1171          1         1            33       4325    1    3  ...     0     0   \n",
      "1280          1         1            33       4395    1    2  ...     0     0   \n",
      "1527          1         1            32       2642    2    3  ...     0     0   \n",
      "1694          1         1            33       2815    2    3  ...     0     0   \n",
      "1734          1         1            33       3786    2    4  ...     0     0   \n",
      "1761          1         1            32       2603    1    3  ...     0     0   \n",
      "1779          1         1            33       4347    1    1  ...     0     0   \n",
      "1809          1         1            33       2663    2    1  ...     0     0   \n",
      "1972          1         1            33       2180    1    3  ...     0     0   \n",
      "2029          1         1            33       3192    1    3  ...     0     0   \n",
      "2077          1         1            33       2392    1    2  ...     0     0   \n",
      "2151          1         1            32        139    2    3  ...     0     0   \n",
      "2189          1         1            33       4363    2    3  ...     0     0   \n",
      "2190          1         1            33       4363    2    3  ...     0     0   \n",
      "2201          1         1            33       2864    1    4  ...     0     0   \n",
      "2245          1         1            33       1246    1    4  ...     0     0   \n",
      "2347          1         1            33       3555    1    2  ...     0     0   \n",
      "2377          1         1            33       6203    1    3  ...     0     0   \n",
      "2727          1         1            33       2900    1    2  ...     0     0   \n",
      "2788          1         1            33       1229    1    2  ...     0     0   \n",
      "2798          1         1            33       3466    1    3  ...     0     0   \n",
      "2839          1         1            33        914    2    2  ...     0     0   \n",
      "3081          1         1            33       4981    1    4  ...     0     0   \n",
      "3170          1         1            33       2177    2    3  ...     0     0   \n",
      "3265          1         1            33       4403    1    3  ...     0     0   \n",
      "3301          1         1            32       2678    2    2  ...     0     0   \n",
      "3391          1         1            33       5574    2    1  ...     0     0   \n",
      "3510          1         1            32        894    2    3  ...     0     0   \n",
      "3537          1         1            32       1456    4    1  ...     0     0   \n",
      "3724          1         1            33       2885    1    5  ...     0     0   \n",
      "3883          1         1            33       2374    1    3  ...     0     0   \n",
      "3984          1         1            32       2963    1    5  ...     0     0   \n",
      "3988          1         1            32       2231    2    2  ...     0     0   \n",
      "4104          1         1            32       1666    2    3  ...     0     0   \n",
      "4376          1         1            33       6291    2    1  ...     0     0   \n",
      "4482          1         1            33       3026    1    2  ...     0     0   \n",
      "4840          1         1            33       3166    1    3  ...     0     0   \n",
      "5205          1         1            33       5409    1    3  ...     0     0   \n",
      "5287          1         1            33       1215    2    4  ...     0     0   \n",
      "5301          1         1            33       2573    1    2  ...     0     0   \n",
      "5576          1         1            32       2676    1    5  ...     0     0   \n",
      "5590          1         1            32       2824    2    2  ...     0     0   \n",
      "5621          1         1            33       5469    2    1  ...     0     0   \n",
      "5728          1         1            33       1427    2    2  ...     0     0   \n",
      "5930          1         1            33       1568    1    3  ...     0     0   \n",
      "6046          1         1            33       3719    1    2  ...     0     0   \n",
      "6357          1         1            33       2397    2    3  ...     0     0   \n",
      "\n",
      "      V9_M  V10_M  V11_M  V12_M  V18_M  V19_AM  V21_M  T_VI  \n",
      "97       0      0      0      0      0       0      0     0  \n",
      "180      0      0      0      0      0       0      0     0  \n",
      "183      0      0      0      0      0       0      0     0  \n",
      "474      0      0      0      0      0       0      0     0  \n",
      "495      0      0      0      0      0       0      0     0  \n",
      "507      0      0      0      0      0       0      0     0  \n",
      "730      0      0      0      0      0       0      0     0  \n",
      "915      0      0      0      0      0       0      0     0  \n",
      "918      0      0      0      0      0       0      0     0  \n",
      "1052     0      0      0      0      0       0      0     0  \n",
      "1171     0      0      0      0      0       0      0     0  \n",
      "1280     0      0      0      0      0       0      0     0  \n",
      "1527     0      0      0      0      0       0      0     0  \n",
      "1694     0      0      0      0      0       0      0     0  \n",
      "1734     0      0      0      0      0       0      0     0  \n",
      "1761     0      0      0      0      0       0      0     0  \n",
      "1779     0      0      0      0      0       0      0     0  \n",
      "1809     0      0      0      0      0       0      0     0  \n",
      "1972     0      0      0      0      0       0      0     0  \n",
      "2029     0      0      0      0      0       0      0     0  \n",
      "2077     0      0      0      0      0       0      0     0  \n",
      "2151     0      0      0      0      0       0      0     0  \n",
      "2189     0      0      0      0      0       0      0     0  \n",
      "2190     0      0      0      0      0       0      0     0  \n",
      "2201     0      0      0      0      0       0      0     0  \n",
      "2245     0      0      0      0      0       0      0     0  \n",
      "2347     0      0      0      0      0       0      0     0  \n",
      "2377     0      0      0      0      0       0      0     0  \n",
      "2727     0      0      0      0      0       0      0     0  \n",
      "2788     0      0      0      0      0       0      0     0  \n",
      "2798     0      0      0      0      0       0      0     0  \n",
      "2839     0      0      0      0      0       0      0     0  \n",
      "3081     0      0      0      0      0       0      0     0  \n",
      "3170     0      0      0      0      0       0      0     0  \n",
      "3265     0      0      0      0      0       0      0     0  \n",
      "3301     0      0      0      0      0       0      0     0  \n",
      "3391     0      0      0      0      0       0      0     0  \n",
      "3510     0      0      0      0      0       0      0     0  \n",
      "3537     0      0      0      0      0       0      0     0  \n",
      "3724     0      0      0      0      0       0      0     0  \n",
      "3883     0      0      0      0      0       0      0     0  \n",
      "3984     0      0      0      0      0       0      0     0  \n",
      "3988     0      0      0      0      0       0      0     0  \n",
      "4104     0      0      0      0      0       0      0     0  \n",
      "4376     0      0      0      0      0       0      0     0  \n",
      "4482     0      0      0      0      0       0      0     0  \n",
      "4840     0      0      0      0      0       0      0     0  \n",
      "5205     0      0      0      0      0       0      0     0  \n",
      "5287     0      0      0      0      0       0      0     0  \n",
      "5301     0      0      0      0      0       0      0     0  \n",
      "5576     0      0      0      0      0       0      0     0  \n",
      "5590     0      0      0      0      0       0      0     0  \n",
      "5621     0      0      0      0      0       0      0     0  \n",
      "5728     0      0      0      0      0       0      0     0  \n",
      "5930     0      0      0      0      0       0      0     0  \n",
      "6046     0      0      0      0      0       0      0     0  \n",
      "6357     0      0      0      0      0       0      0     0  \n",
      "\n",
      "[57 rows x 133 columns]\n",
      "Empty DataFrame\n",
      "Columns: [CODUSU, ANO4_x, TRIMESTRE_x, NRO_HOGAR, REALIZADA, REGION_x, AGLOMERADO_x, PONDERA_x, IV1, IV2, IV3, IV4, IV5, IV6, IV7, IV8, IV9, IV10, IV11, IV12_1, IV12_2, IV12_3, II1, II2, II3, II3_1, II4_1, II4_2, II4_3, II5, II5_1, II6, II6_1, II7, II8, II9, V1, V2, V21, V22, V3, V4, V5, V6, V7, V8, V9, V10, V11, V12, V13, V14, V15, V16, V17, V18, V19_A, V19_B, IX_TOT, IX_MEN10, IX_MAYEQ10, ITF_x, DECIFR_x, RDECIFR_x, GDECIFR_x, ADECIFR_x, IPCF_x, DECCFR_x, RDECCFR_x, GDECCFR_x, ADECCFR_x, PONDIH_x, VII1_1, VII1_2, VII2_1, VII2_2, VII2_3, VII2_4, COMPONENTE, H15, CH03, CH04, CH06, CH07, CH08, CH09, CH10, CH11, CH12, CH13, CH15, CH16, NIVEL_ED, ESTADO, CAT_OCUP, CAT_INAC, PP02C1, PP02C2, PP02C3, PP02C4, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 133 columns]\n",
      "Empty DataFrame\n",
      "Columns: [CODUSU, ANO4_x, TRIMESTRE_x, NRO_HOGAR, REALIZADA, REGION_x, AGLOMERADO_x, PONDERA_x, IV1, IV2, IV3, IV4, IV5, IV6, IV7, IV8, IV9, IV10, IV11, IV12_1, IV12_2, IV12_3, II1, II2, II3, II3_1, II4_1, II4_2, II4_3, II5, II5_1, II6, II6_1, II7, II8, II9, V1, V2, V21, V22, V3, V4, V5, V6, V7, V8, V9, V10, V11, V12, V13, V14, V15, V16, V17, V18, V19_A, V19_B, IX_TOT, IX_MEN10, IX_MAYEQ10, ITF_x, DECIFR_x, RDECIFR_x, GDECIFR_x, ADECIFR_x, IPCF_x, DECCFR_x, RDECCFR_x, GDECCFR_x, ADECCFR_x, PONDIH_x, VII1_1, VII1_2, VII2_1, VII2_2, VII2_3, VII2_4, COMPONENTE, H15, CH03, CH04, CH06, CH07, CH08, CH09, CH10, CH11, CH12, CH13, CH15, CH16, NIVEL_ED, ESTADO, CAT_OCUP, CAT_INAC, PP02C1, PP02C2, PP02C3, PP02C4, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 133 columns]\n",
      "Empty DataFrame\n",
      "Columns: [CODUSU, ANO4_x, TRIMESTRE_x, NRO_HOGAR, REALIZADA, REGION_x, AGLOMERADO_x, PONDERA_x, IV1, IV2, IV3, IV4, IV5, IV6, IV7, IV8, IV9, IV10, IV11, IV12_1, IV12_2, IV12_3, II1, II2, II3, II3_1, II4_1, II4_2, II4_3, II5, II5_1, II6, II6_1, II7, II8, II9, V1, V2, V21, V22, V3, V4, V5, V6, V7, V8, V9, V10, V11, V12, V13, V14, V15, V16, V17, V18, V19_A, V19_B, IX_TOT, IX_MEN10, IX_MAYEQ10, ITF_x, DECIFR_x, RDECIFR_x, GDECIFR_x, ADECIFR_x, IPCF_x, DECCFR_x, RDECCFR_x, GDECCFR_x, ADECCFR_x, PONDIH_x, VII1_1, VII1_2, VII2_1, VII2_2, VII2_3, VII2_4, COMPONENTE, H15, CH03, CH04, CH06, CH07, CH08, CH09, CH10, CH11, CH12, CH13, CH15, CH16, NIVEL_ED, ESTADO, CAT_OCUP, CAT_INAC, PP02C1, PP02C2, PP02C3, PP02C4, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 133 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f_filtrada[f_filtrada[\"ITF_x\"] < 0])\n",
    "#Obtenemos un dataframe vacío, por lo que no hay observaciones que cumplan con esas características.\n",
    "\n",
    "print(f_filtrada[f_filtrada[\"IPCF_x\"] < 0])\n",
    "#Obtenemos un dataframe vacío, por lo que no hay observaciones que cumplan con esas características.\n",
    "\n",
    "print(f_filtrada[f_filtrada[\"P21\"] < 0])\n",
    "#Obtenemos un dataframe con datos de ingreso negativos, por lo que procedemos a eliminarlos.\n",
    "\n",
    "print(f_filtrada[f_filtrada[\"P47T\"] < 0])\n",
    "#Obtenemos un dataframe con datos de ingreso negativos, por lo que procedemos a eliminarlos.\n",
    "\n",
    "print(f_filtrada[f_filtrada[\"CH06\"] < 0])\n",
    "#Obtenemos un dataframe con datos de edad negativos, por lo que procedemos a eliminarlos.\n",
    "\n",
    "#Eliminamos las observaciones con edades negativas.\n",
    "f_filtrada = f_filtrada[f_filtrada.CH06>=0]\n",
    "\n",
    "#Eliminamos las observaciones con ingreso negativo.\n",
    "f_filtrada = f_filtrada[f_filtrada.P21>=0]\n",
    "\n",
    "#Eliminamos las observaciones con ingreso negativo.\n",
    "f_filtrada = f_filtrada[f_filtrada.P47T>=0]\n",
    "\n",
    "#Chequeamos que al imprimir el dataframe seleccionando edades negativas devuelva un dataframe vacío.\n",
    "print(f_filtrada[f_filtrada[\"CH06\"] < 0])\n",
    "\n",
    "#Chequeamos que al imprimir el dataframe seleccionando ingresos negativos devuelva un dataframe vacío.\n",
    "print(f_filtrada[f_filtrada[\"P21\"] < 0])\n",
    "\n",
    "#Chequeamos que al imprimir el dataframe seleccionando ingresos negativos devuelva un dataframe vacío.\n",
    "print(f_filtrada[f_filtrada[\"P47T\"] < 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61db240",
   "metadata": {},
   "source": [
    "#### 4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c68b2fb",
   "metadata": {},
   "source": [
    "Construimos una variable que indique la proporción de niños menores de 10 años en el hogar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddc12f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_filtrada[\"niños_prop\"] = f_filtrada[\"IX_MEN10\"]/f_filtrada[\"IX_TOT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7316aa9",
   "metadata": {},
   "source": [
    "Construimos una variable que identifique si el cónyuge del jefe de hogar trabaja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b352717",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_filtrada[\"conyuge_trabaja\"] = 0\n",
    "\n",
    "for index, row in f_filtrada.iterrows():\n",
    "    if row[\"CH03\"] == 2:\n",
    "        if row[\"ESTADO\"] == 1:\n",
    "            f_filtrada.loc[index, \"conyuge_trabaja\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e812f5a",
   "metadata": {},
   "source": [
    "Construimos una variable que indique si quien contesta la encuesta es migrante. Entendemos como migrantes a aquellos individuos que no son oriundos de la localidad en la que residen y además se desplazaron en los últimos 5 años. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fae41ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_filtrada[\"migrante\"] = 0\n",
    "\n",
    "for index, row in f_filtrada.iterrows():\n",
    "    if (row[\"CH15\"] != 1 & row[\"CH15\"] != 2):\n",
    "        if (row[\"CH16\"] != 1  & row[\"CH16\"] != 2):\n",
    "            f_filtrada.loc[index, \"migrante\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce9117",
   "metadata": {},
   "source": [
    "<span style='background :yellow' > Piensan que los migrantes van a ser predictores de pobres o no pobres? Está bueno que justifiquen por qué agregan las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed79bb",
   "metadata": {},
   "source": [
    "### 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feebac9",
   "metadata": {},
   "source": [
    "Creamos un grafico de dispersión entre la proporción de niños en el hogar y el máximo nivel educativo de quien contesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d763c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = f_filtrada[\"CH12\"]\n",
    "y = f_filtrada[\"niños_prop\"]\n",
    "colors = np.random.rand(5231)\n",
    "area = (20 * np.random.rand(5231))**1\n",
    "plt.scatter(x, y, s=area, c=colors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c16fe9",
   "metadata": {},
   "source": [
    "<span style='background :yellow' > Faltan ejes y algun tipo de explicación (aunque sea una línea), tienen que tener cuidado con cómo está codeada nivel educativo. Por ejemplo, si hubiese un nueve sería \"Educación especial (discapacitado)\", que no es \"mayor nivel educativo\" que \"Posgrado universitario\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89a33a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Heatmap de matriz de correlación')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from heatmap import heatmap, corrplot\n",
    "import seaborn as sns\n",
    "data_cor = f_filtrada[['CH04', 'CH07', 'CH08', 'NIVEL_ED', 'ESTADO', 'niños_prop', 'conyuge_trabaja','migrante']]\n",
    "data_cor\n",
    "#Armamos la matriz de correlación\n",
    "corr = data_cor.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "#Cambiamos las labels\n",
    "ax.set_xticklabels(\n",
    "    ax.set_xticklabels([\"Sexo\", \"Estado civil\", \"Cobertura médica\", \"Nivel educativo\", \"Actividad\", \"Niños\", \"Conyuge trabaja\", \"Migrante\"]),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "ax.set_yticklabels(\n",
    "    ax.set_yticklabels([\"Sexo\", \"Estado civil\", \"Cobertura médica\", \"Nivel educativo\", \"Actividad\", \"Niños\", \"Conyuge trabaja\", \"Migrante\"]),\n",
    "    rotation=0,\n",
    ");\n",
    "#Sumamos el título\n",
    "plt.title(\"Heatmap de matriz de correlación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0a09c9",
   "metadata": {},
   "source": [
    "#### 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03f3c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la tabla de equivalencias \n",
    "tabla_adulto=pd.read_excel(\"tabla_adulto_equiv.xlsx\", header = 4, nrows=23, )\n",
    "tabla_adulto.rename({'Unnamed: 0':'Edad','Unnamed: 1':'Mujeres','Unnamed: 2':'Varones'}, axis=1, inplace = True)\n",
    "# Generamos una nueva tabla para mujeres\n",
    "tabla_adulto_m = tabla_adulto[[\"Edad\",\"Mujeres\"]]\n",
    "\n",
    "# Generamos una nueva tabla para varones\n",
    "tabla_adulto_v = tabla_adulto[[\"Edad\",\"Varones\"]]\n",
    "# Generamos Ids para mujeres\n",
    "N=0 \n",
    "temp = 0\n",
    "lista = []\n",
    "for i in range(23):\n",
    "    temp = \"M\" + str(N)\n",
    "    lista.append(temp)\n",
    "    N=N+1\n",
    "\n",
    "tabla_adulto_m[\"id\"]=lista\n",
    "tabla_adulto_m[\"Varon\"]=0\n",
    "tabla_adulto_m.rename({'Mujeres':'Valor'}, axis=1, inplace = True)\n",
    "# Generamos Ids para varones\n",
    "N=0 \n",
    "temp_v = 0\n",
    "lista_v = []\n",
    "for i in range(23):\n",
    "    temp_v = \"V\" + str(N)\n",
    "    lista_v.append(temp_v)\n",
    "    N=N+1\n",
    "\n",
    "tabla_adulto_v[\"id\"]=lista_v\n",
    "tabla_adulto_v[\"Varon\"]=1\n",
    "tabla_adulto_v.rename({'Varones':'Valor'}, axis=1, inplace = True)\n",
    "\n",
    "# Unimos las tablas verticalmente\n",
    "tabla_adulto_total = tabla_adulto_v.append(tabla_adulto_m) \n",
    "tabla_adulto_total.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86e9c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un loop para asignar los códigos correspondientes (de sexo y edad) a cada observación de la base original\n",
    "for index, row in f_filtrada.iterrows(): \n",
    "    if row[\"CH06\"]<1:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V0\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M0\"\n",
    "    elif row[\"CH06\"]==1:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V1\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M1\"\n",
    "    elif row[\"CH06\"]==2:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V2\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M2\"\n",
    "    elif row[\"CH06\"]==3:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V3\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M3\"\n",
    "    elif row[\"CH06\"]==4:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V4\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M4\"\n",
    "    elif row[\"CH06\"]==5:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V5\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M5\"\n",
    "    elif row[\"CH06\"]==6:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V6\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M6\"\n",
    "    elif row[\"CH06\"]==7:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V7\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M7\"\n",
    "    elif row[\"CH06\"]==8:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V8\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M8\"\n",
    "    elif row[\"CH06\"]==9:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V9\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M9\"\n",
    "    elif row[\"CH06\"]==10:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V10\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M10\"\n",
    "    elif row[\"CH06\"]==11:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V11\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M11\"\n",
    "    elif row[\"CH06\"]==12:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V12\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M12\"\n",
    "    elif row[\"CH06\"]==13:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V13\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M13\"\n",
    "    elif row[\"CH06\"]==14:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V14\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M14\"\n",
    "    elif row[\"CH06\"]==15:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V15\"\n",
    "        else:\n",
    "            f_filtrada.loc[index,\"id\"]=\"M15\"\n",
    "    elif row[\"CH06\"]==16:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V16\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M16\"\n",
    "    elif row[\"CH06\"]==17:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V17\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M17\"\n",
    "    elif (row[\"CH06\"]> 17 and row[\"CH06\"]<30):\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V18\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M18\"\n",
    "    elif (row[\"CH06\"]>= 30 and row[\"CH06\"]<46):\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V19\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M19\"\n",
    "    elif (row[\"CH06\"]>= 46 and row[\"CH06\"]<61):\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V20\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M20\"\n",
    "    elif (row[\"CH06\"]>= 61 and row[\"CH06\"]<75):\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V21\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M21\"\n",
    "    else:\n",
    "        if row[\"CH04\"]==1:\n",
    "            f_filtrada.loc[index,\"id\"]=\"V22\"\n",
    "        else: \n",
    "            f_filtrada.loc[index,\"id\"]=\"M22\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c3c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chequeamos que se hayan asignado correctamente los id\n",
    "f_filtrada[[\"CH04\",\"CH06\",\"id\"]] \n",
    "# Unimos la tabla original con la tabla de equivalencias calóricas, a partir de los id generados \n",
    "df_ba_unido = pd.merge(f_filtrada, tabla_adulto_total, on=\"id\")\n",
    "# Renombramos la variable de adulto_equiv \n",
    "df_ba_unido.rename({'Valor':'adulto_equiv'}, axis=1, inplace = True)\n",
    "# Sumamos los valores calóricos por hogar y lo asignamos como una nueva variable a cada individuo\n",
    "df_ba_unido[\"ad_equiv_hogar\"] = df_ba_unido.groupby([\"CODUSU\", \"NRO_HOGAR\"])[\"adulto_equiv\"].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "974e4aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de personas que no respondieron cuál es su ingreso total familiar es: 1542\n",
      "1       435000\n",
      "2       120000\n",
      "3        15000\n",
      "6       210000\n",
      "8        63000\n",
      "         ...  \n",
      "5224     22000\n",
      "5225     16000\n",
      "5226    160000\n",
      "5228     53500\n",
      "5230    282000\n",
      "Name: ITF_x, Length: 3689, dtype: int64\n",
      "0       0\n",
      "4       0\n",
      "5       0\n",
      "7       0\n",
      "14      0\n",
      "       ..\n",
      "5218    0\n",
      "5219    0\n",
      "5221    0\n",
      "5227    0\n",
      "5229    0\n",
      "Name: ITF_x, Length: 1542, dtype: int64\n",
      "1        69353.9820\n",
      "2        96551.6220\n",
      "3        97639.5276\n",
      "6        89208.2592\n",
      "8        96551.6220\n",
      "           ...     \n",
      "5224    132180.5304\n",
      "5225     60922.7136\n",
      "5226     60650.7372\n",
      "5228     61194.6900\n",
      "5230     88664.3064\n",
      "Name: ingreso_necesario, Length: 3689, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Chequeamos la cantidad de personas que no declararon el ITF\n",
    "print(\"La cantidad de personas que no respondieron cuál es su ingreso total familiar es:\", df_ba_unido['ITF_x'].value_counts()[0])\n",
    "# Guardamos en un nuevo data frame las personas que sí respondieron a ITF\n",
    "respondieron = df_ba_unido[df_ba_unido[\"ITF_x\"]!=0]\n",
    "# Chequeamos que se haya guardado bien\n",
    "print(respondieron[\"ITF_x\"])\n",
    "# Guardamos en un nuevo data frame las personas que no respondieron a ITF\n",
    "norespondieron = df_ba_unido[df_ba_unido[\"ITF_x\"]==0]\n",
    "# Chequeamos que se haya guardado bien\n",
    "print(norespondieron[\"ITF_x\"])\n",
    "# Agregamos la columna a la base de los que respondieron\n",
    "respondieron[\"ingreso_necesario\"] = 27197.64 * respondieron[\"ad_equiv_hogar\"]\n",
    "#respondieron[[\"ingreso_necesario\" \"ad_equiv_hogar\"]]\n",
    "print(respondieron [\"ingreso_necesario\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8cd99",
   "metadata": {},
   "source": [
    "#### 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63f032a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la columna que identifica si el individuo es pobre\n",
    "for index, row in respondieron.iterrows(): \n",
    "    if row[\"ITF_x\"]< respondieron.loc[index, \"ingreso_necesario\"]:\n",
    "        respondieron.loc [index,\"pobre\"] = 1\n",
    "    else:\n",
    "        respondieron.loc[index, \"pobre\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1111629",
   "metadata": {},
   "source": [
    "#### 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c2f325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             CODUSU  ANO4_x  TRIMESTRE_x  NRO_HOGAR  \\\n",
      "1     TQRMNORSUHLMNPCDEIIAD00718267    2022            1          1   \n",
      "2     TQRMNOQUUHLMTSCDEIJAH00719592    2022            1          1   \n",
      "3     TQRMNORRUHLLKNCDEIJAH00718712    2022            1          1   \n",
      "6     TQRMNOQXUHJMMUCDEIJAH00693031    2022            1          1   \n",
      "8     TQRMNOPQPHMMQLCDEIJAH00701137    2022            1          1   \n",
      "...                             ...     ...          ...        ...   \n",
      "5224  TQRMNORQYHMMMPCDEIJAH00698194    2022            1          1   \n",
      "5225  TQSMNOTXQHKMLQCDEIJAH00780680    2022            1          1   \n",
      "5226  TQRMNOQWPHKOTMCDEIJAH00780657    2022            1          1   \n",
      "5228  TQRMNOSRWHLOLSCDEIJAH00719039    2022            1          1   \n",
      "5230  TQRMNOQRXHMMPPCDEIJAH00780782    2022            1          1   \n",
      "\n",
      "      REALIZADA  REGION_x  AGLOMERADO_x  PONDERA_x  IV1  IV2  ...  niños_prop  \\\n",
      "1             1         1            32       2785    2    3  ...    0.000000   \n",
      "2             1         1            33       2461    1    4  ...    0.000000   \n",
      "3             1         1            33       2964    2    3  ...    0.000000   \n",
      "6             1         1            33       1876    1    9  ...    0.000000   \n",
      "8             1         1            33       1983    1    4  ...    0.000000   \n",
      "...         ...       ...           ...        ...  ...  ...  ...         ...   \n",
      "5224          1         1            33       2913    1    2  ...    0.428571   \n",
      "5225          1         1            33       1864    1    1  ...    0.333333   \n",
      "5226          1         1            33       4796    1    3  ...    0.333333   \n",
      "5228          1         1            33       2783    1    3  ...    0.333333   \n",
      "5230          1         1            33       2622    1    4  ...    0.250000   \n",
      "\n",
      "      conyuge_trabaja  migrante   id          Edad  adulto_equiv  Varon  \\\n",
      "1                   0         0  V20  46 a 60 años          1.00      1   \n",
      "2                   0         0  V20  46 a 60 años          1.00      1   \n",
      "3                   0         0  V20  46 a 60 años          1.00      1   \n",
      "6                   0         0  V20  46 a 60 años          1.00      1   \n",
      "8                   0         0  V20  46 a 60 años          1.00      1   \n",
      "...               ...       ...  ...           ...           ...    ...   \n",
      "5224                0         0   V2        2 años          0.46      1   \n",
      "5225                0         0   V2        2 años          0.46      1   \n",
      "5226                0         0   V2        2 años          0.46      1   \n",
      "5228                0         0   V2        2 años          0.46      1   \n",
      "5230                0         0   V2        2 años          0.46      1   \n",
      "\n",
      "      ad_equiv_hogar  ingreso_necesario  pobre  \n",
      "1               2.55         69353.9820    0.0  \n",
      "2               3.55         96551.6220    0.0  \n",
      "3               3.59         97639.5276    1.0  \n",
      "6               3.28         89208.2592    0.0  \n",
      "8               3.55         96551.6220    1.0  \n",
      "...              ...                ...    ...  \n",
      "5224            4.86        132180.5304    1.0  \n",
      "5225            2.24         60922.7136    1.0  \n",
      "5226            2.23         60650.7372    0.0  \n",
      "5228            2.25         61194.6900    1.0  \n",
      "5230            3.26         88664.3064    0.0  \n",
      "\n",
      "[3689 rows x 143 columns]\n"
     ]
    }
   ],
   "source": [
    "print(respondieron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc51a76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El pocentaje de hogares bajo la linea de pobreza es 0.34064281543033087\n"
     ]
    }
   ],
   "source": [
    "pondih = respondieron.groupby(['CODUSU', 'NRO_HOGAR']).agg({'PONDIH_x' : 'sum', \"pobre\" : \"mean\"})\n",
    "# Para dentro de un mismo hogar todos deberían tener el mismo valor de Pobre, así que calcular el promedio va a dar que es pobre si todos son pobres y viceversa \n",
    "pondih.loc[pondih['pobre'] == 1, \"PONDIH_x\"].sum() \n",
    "pondih[\"PONDIH_x\"].sum()\n",
    "# Calculamos el porcentaje de hogares bajo la linea de pobreza \n",
    "hogares_pobres = (pondih.loc[pondih['pobre'] == 1, \"PONDIH_x\"].sum()) / (pondih[\"PONDIH_x\"].sum())\n",
    "print(\"El pocentaje de hogares bajo la linea de pobreza es\", hogares_pobres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28791e16",
   "metadata": {},
   "source": [
    "La tasa de pobreza que obtenemos se asemeja a la del INDEC. Para el primer semestre de 2022 para AMBA obtenemos una tasa de 34.06%, mientras que en el INDEC la tasa de pobreza para esta misma región es de 28.2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edd4acfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La suma del PONDIH de los hogares pobres es 1262824\n",
      "La suma del PONDIH de todos los hogares 4978383\n",
      "La tasa de hogares bajo la linea de pobreza de AMBA es 25.366148004281712 %\n"
     ]
    }
   ],
   "source": [
    "#Concatenamos CODUSU y el número de hogar para poder quedarnos solo con una observación por hogar.\n",
    "for index, row in respondieron.iterrows(): \n",
    "    respondieron.loc[index, \"hogar\"] = str(respondieron.loc[index, \"CODUSU\"]) + str(respondieron.loc[index, \"NRO_HOGAR\"])    \n",
    "\n",
    "#Eliminamos las observaciones repetidas de un mismo hogar\n",
    "respondieron_hogares = respondieron.drop_duplicates(subset = \"hogar\", keep='first')\n",
    "\n",
    "# Sumamos los ponderadores de pobres y no pobres  \n",
    "pond_pob = 0\n",
    "\n",
    "for index, row in respondieron_hogares.iterrows(): \n",
    "    if respondieron_hogares.loc [index,\"pobre\"] == 1:\n",
    "        pond_pob += respondieron_hogares.loc [index,\"PONDIH_x\"]\n",
    "    else:\n",
    "        continue\n",
    "print(\"La suma del PONDIH de los hogares pobres es\", pond_pob)\n",
    "\n",
    "#Sumamos los ponderadores de todos los hogares\n",
    "pond_tot = respondieron_hogares[\"PONDIH_x\"].sum()\n",
    "print(\"La suma del PONDIH de todos los hogares\",pond_tot)\n",
    "\n",
    "#Calculamos la tasa de pobreza por hogar\n",
    "print(\"La tasa de hogares bajo la linea de pobreza de AMBA es\", (pond_pob/pond_tot*100),\"%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f248f96",
   "metadata": {},
   "source": [
    "La tasa de pobreza que obtenemos se asemeja a la del INDEC. Para el primer semestre de 2022 para AMBA obtenemos una tasa de 25.36%, mientras que en el INDEC la tasa de pobreza para esta misma región es de 28.2%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ef87c",
   "metadata": {},
   "source": [
    "### Parte II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ba826",
   "metadata": {},
   "source": [
    "#### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aef832ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def evalua_metodo(nombre_modelo, X_train, y_train, X_test, y_test, p=None, c=None, n_components=None, k_rango_min=None, \n",
    "                  k_rango_max=None) :\n",
    "    \n",
    "    '''\n",
    "    Esta función ajusta los datos al modelo provisto y calcula las siguientes métricas:\n",
    "    curva de ROC, valores AUC y el accuracy score del método. Automáticamente la función importa distintos paquetes de\n",
    "    sklearn.\n",
    "    Input:\n",
    "        modelo (str): Modelo a utilizar. Las opciones son \"logit\", \"adl\" (análisis discriminante lineal), \"knn\" (vecinos\n",
    "        cercanos), \"arbol\" (árbol de regresión), \"bagging\" (con árboles de regresión), \"random_forest\" (con árboles de regresión),\n",
    "        \"gradient_boosting\" (gradient boosting de árboles de regresión)\n",
    "        X_train (df): Partición de la muestra de predictores para entrenamiento\n",
    "        y_train (df): Partición de la muestra de outcomes para entrenamiento\n",
    "        X_test (df): Partición de la muestra de predictores para testeo\n",
    "        y_test (df): Partición de la muestra de outcomes para testeo\n",
    "        p(float): Parámetro de penalty para regresión logística\n",
    "        c(float): Parámetro que indica la inversa del hiperparámetro para la regresión logística\n",
    "        n_components(float): Número de componentes para el análisis discriminante lineal\n",
    "        k_rango_min(int): Mínimo de vecinos cercanos a evaluar para el método de vecinos cercanos\n",
    "        k_rango_max(int): Máximo de vecinos cercanos a evaluar para el método de vecinos cercanos \n",
    "        \n",
    "        \n",
    "    Output:\n",
    "        metricas (dict): Métricas de interés. Las métricas son falsos positivos, falsos negativos, verdaderos positivos,\n",
    "        verdaderos negativos, curva de ROC, valores AUC, la precisión, el accuracy score del método, Error Cuadrático\n",
    "        Medio, gráfico del árbol de decisión. \n",
    "        \n",
    "    '''\n",
    "\n",
    "    metricas = {}\n",
    "    \n",
    "    MODELOS = {\"logit\": LogisticRegression(), \"adl\": LinearDiscriminantAnalysis(), \"knn\": KNeighborsClassifier(), \"arbol\": DecisionTreeRegressor(), \"bagging\": BaggingRegressor(), \"random_forest\": RandomForestRegressor(), \"gradient_boosting\": GradientBoostingRegressor()}\n",
    "    \n",
    "    modelo = MODELOS[nombre_modelo]\n",
    "    \n",
    "    if nombre_modelo == \"logit\":\n",
    "        # Ajustamos el clasificador con fit con la base de entrenamiento\n",
    "        log_reg = LogisticRegression(penalty = p, C= c, max_iter=10000, solver=\"liblinear\").fit(X_train, y_train)\n",
    "        # Predecimos con la base test\n",
    "        y_pred = log_reg.predict(X_test)\n",
    "        # Armamos la matriz de confusión.\n",
    "        tn, fp , fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        #Calculamos los valores de AUC\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred) \n",
    "        # Hacemos el accuracy score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        k_usados = []\n",
    "        #Calculamos la precisión\n",
    "        prec = tp/(tp+fp)\n",
    "        # Calculamos el ECM \n",
    "        ecm = mean_squared_error(y_test, y_pred)\n",
    "        depth_optimo = []\n",
    "    \n",
    "    if nombre_modelo == \"adl\":\n",
    "        # Entrenamos el modelo para el análisis discriminante lineal\n",
    "        lda = LinearDiscriminantAnalysis(n_components=n_components)        \n",
    "        lda = lda.fit(X= X_train, y=y_train)\n",
    "        \n",
    "        # Realizamos las predicciones para la muestra de testeo\n",
    "        y_pred_lda = lda.predict(X_test)\n",
    "        # Armamos la matriz de confusión.\n",
    "        tn, fp , fn, tp = confusion_matrix(y_test, y_pred_lda).ravel() \n",
    "        # Calculamos los valores de AUC\n",
    "        auc = roc_auc_score(y_test, y_pred_lda)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_lda)\n",
    "        # Calculamos el accuracy score para análisis lineal discriminante\n",
    "        accuracy = accuracy_score(y_test, y_pred_lda)\n",
    "        k_usados = []\n",
    "        #Calculamos la precisión\n",
    "        prec = tp/(tp+fp)\n",
    "        # Calculamos el ECM \n",
    "        ecm = mean_squared_error(y_test, y_pred_lda)\n",
    "        depth_optimo = []\n",
    "\n",
    "    if nombre_modelo == \"knn\":\n",
    "        #Determinamos el k a utilizar\n",
    "        k_range = range(k_rango_min, k_rango_max)\n",
    "        scores = {}      \n",
    "        scores_list = []\n",
    "        for k in k_range:\n",
    "                knn = KNeighborsClassifier(n_neighbors=k)\n",
    "                knn.fit(X_train, y_train)\n",
    "                y_pred_knn = knn.predict(X_test)\n",
    "                scores[k] = accuracy_score(y_test, y_pred_knn)\n",
    "                scores_list.append(accuracy_score(y_test, y_pred_knn))\n",
    "        a_optimo = min(scores_list)\n",
    "        k_optimo = scores_list.index(a_optimo) + 1\n",
    "        # Entrenamos al modelo con el método de KNN, tomando el k optimo entre 1 y 10\n",
    "        knn = KNeighborsClassifier(n_neighbors= k_optimo)\n",
    "        knn.fit(X_train, y_train)\n",
    "        # Realizamos las predicciones para la muestra de testeo\n",
    "        y_pred_knn = knn.predict(X_test)\n",
    "        # Armamos la matriz de confusión.\n",
    "        tn, fp , fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()         \n",
    "        # Calculamos los valores de AUC\n",
    "        auc = roc_auc_score(y_test, y_pred_knn)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_knn)\n",
    "        # Calculamos el accuracy score\n",
    "        accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "        k_usados = k_optimo\n",
    "        #Calculamos la precisión\n",
    "        prec = tp/(tp+fp)\n",
    "        # Calculamos el ECM \n",
    "        ecm = mean_squared_error(y_test, y_pred_knn)\n",
    "        depth_optimo = []\n",
    "        \n",
    "    if nombre_modelo == \"arbol\" :             \n",
    "        mses = list()\n",
    "        max_attributes = len(list(X_test))\n",
    "        depth_range = range(1, max_attributes + 1)\n",
    "\n",
    "        for depth in depth_range:\n",
    "            tree_model = DecisionTreeRegressor(max_depth = depth)\n",
    "            model = tree_model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_pred, y_test)\n",
    "            mses.append(mse)            \n",
    "            \n",
    "        ecm_optimo = min(mses)\n",
    "        depth_optimo = mses.index(ecm_optimo) + 1\n",
    "        \n",
    "        # Creamos un arbol \n",
    "        decision_tree = DecisionTreeRegressor(max_depth = depth_optimo)\n",
    "        model = decision_tree.fit(X= X_train, y=y_train)\n",
    "        # Predición sobre los datos de test\n",
    "        y_pred_arbol = decision_tree.predict(X_test)\n",
    "        # Armamos la matriz de confusión.\n",
    "        tn, fp , fn, tp = confusion_matrix(y_test, y_pred_arbol).ravel() \n",
    "        # Calculamos los valores de AUC\n",
    "        auc = roc_auc_score(y_test, y_pred_arbol)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_arbol)\n",
    "        # Calculamos el accuracy score \n",
    "        accuracy = accuracy_score(y_test, y_pred_arbol)\n",
    "        k_usados = []\n",
    "        #Calculamos la precisión\n",
    "        prec = tp/(tp+fp)\n",
    "        # Calculamos el ECM \n",
    "        ecm = mean_squared_error(y_test, y_pred_arbol)\n",
    "        \n",
    "    if nombre_modelo == \"bagging\":\n",
    "        \n",
    "        regressor = BaggingClassifier(n_estimators=10, max_samples= 200, random_state=0) \n",
    "        regressor.fit(X_train, y_train) \n",
    "        y_pred_bagging = regressor.predict(X_test)\n",
    "        # Armamos la matriz de confusión.\n",
    "        tn, fp , fn, tp = confusion_matrix(y_test, y_pred_bagging).ravel() \n",
    "        # Calculamos los valores de AUC\n",
    "        auc = roc_auc_score(y_test, y_pred_bagging)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_bagging)\n",
    "        # Calculamos el accuracy score \n",
    "        accuracy = accuracy_score(y_test, y_pred_bagging)\n",
    "        k_usados = []\n",
    "        #Calculamos la precisión\n",
    "        prec = tp/(tp+fp)\n",
    "        # Calculamos el ECM \n",
    "        ecm = mean_squared_error(y_test, y_pred_bagging)\n",
    "        depth_optimo = []\n",
    "        \n",
    "    if nombre_modelo == \"random_forest\":\n",
    "        regressor = RandomForestClassifier(n_estimators=10, max_samples=200, max_features=9, random_state=0) \n",
    "        regressor.fit(X_train, y_train) \n",
    "        y_pred_randomf = regressor.predict(X_test)\n",
    "        # Armamos la matriz de confusión.\n",
    "        tn, fp , fn, tp = confusion_matrix(y_test, y_pred_randomf).ravel() \n",
    "        # Calculamos los valores de AUC\n",
    "        auc = roc_auc_score(y_test, y_pred_randomf)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_randomf)\n",
    "        # Calculamos el accuracy score \n",
    "        accuracy = accuracy_score(y_test, y_pred_randomf)\n",
    "        k_usados = []\n",
    "        #Calculamos la precisión\n",
    "        prec = tp/(tp+fp)\n",
    "        # Calculamos el ECM \n",
    "        ecm = mean_squared_error(y_test, y_pred_randomf)\n",
    "        depth_optimo = []\n",
    "        \n",
    "    if nombre_modelo == \"gradient_boosting\":\n",
    "        regressor = GradientBoostingClassifier(n_estimators=10, max_depth=9, random_state=0) \n",
    "        regressor.fit(X_train, y_train) \n",
    "        y_pred_gb = regressor.predict(X_test)\n",
    "        # Armamos la matriz de confusión.\n",
    "        tn, fp , fn, tp = confusion_matrix(y_test, y_pred_gb).ravel() \n",
    "        # Calculamos los valores de AUC\n",
    "        auc = roc_auc_score(y_test, y_pred_gb)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_gb)\n",
    "        # Calculamos el accuracy score \n",
    "        accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "        k_usados = []\n",
    "        #Calculamos la precisión\n",
    "        prec = tp/(tp+fp)\n",
    "        # Calculamos el ECM \n",
    "        ecm = mean_squared_error(y_test, y_pred_gb)\n",
    "        depth_optimo = []\n",
    "\n",
    "    metricas = {\"Falsos positivos\": fp, \"Falsos negativos\": fn, \"Verdaderos positivos\": tp, \"Verdaderos negativos\": tn, \"Valor AUC\" : \"%.4f\" %auc, \"Accuracy score\": \"%.2f\" %accuracy, \"Precisión\": prec, \"ECM\": ecm}\n",
    "    \n",
    "    return metricas, k_usados, depth_optimo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66735fe7",
   "metadata": {},
   "source": [
    "<span style='background :yellow' > Buena parte de cada condicional es idéntico al resto, podrían evitarse bastantes líneas simplemente sacando eso afuera de los condicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55572ae",
   "metadata": {},
   "source": [
    "#### 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd518496",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def cross_validation(nombre_modelo, k_particiones, X, y, p, c, n_components, k_rango_min, k_rango_max) :\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Esta función realiza validación cruzada con \"k_particiones\" iteraciones. Utiliza la función evalua_metodo en cada una de\n",
    "    las iteraciones y para cada una de las particiones. \n",
    "    Input:\n",
    "        modelo (str): Modelo a utilizar. Las opciones son \"logit\", \"adl\" (análisis discriminante lineal), \"knn\" (vecinos\n",
    "        cercanos) \n",
    "        k_particiones(int): Número entero que indica la cantidad de particiones a utilizar en la validación cruzada\n",
    "        X(df): Muestra de predictores\n",
    "        y(df): Muestra de outcomes\n",
    "        p(float): Parámetro de penalty para regresión logística\n",
    "        c(float): Parámetro que indica la inversa del hiperparámetro para la regresión logística\n",
    "        n_components(float): Número de componentes para el análisis discriminante lineal\n",
    "        k_rango_min(int): Mínimo de vecinos cercanos a evaluar para el método de vecinos cercanos\n",
    "        k_rango_max(int): Máximo de vecinos cercanos a evaluar para el método de vecinos cercanos\n",
    "    Output:\n",
    "        outputs (dict): Métricas de interés. El error Cuadrático Medio promedio de los modelos calculados\n",
    "        \n",
    "    '''\n",
    "        \n",
    "    K = k_particiones\n",
    "\n",
    "    ecms = pd.DataFrame(columns=[\"particion\", \"ECM\"])\n",
    "\n",
    "    for i in range(2, 10):   \n",
    "\n",
    "        kf = KFold(n_splits=K, shuffle=True, random_state=100)\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(X)):   \n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            sc = StandardScaler()\n",
    "\n",
    "            # Estandarizamos las observaciones de entrenamiento\n",
    "            X_train_transformed = pd.DataFrame(sc.fit_transform(X_train),index=X_train.index, columns=X_train.columns)\n",
    "\n",
    "            # Estandarizamos las observaciones de test\n",
    "            X_test_transformed = pd.DataFrame(sc.transform(X_test),index=X_test.index, columns=X_test.columns)\n",
    "            \n",
    "            X_train = X_train_transformed\n",
    "            X_test = X_test_transformed\n",
    "\n",
    "            metricas, k_usados, depth_optimo = evalua_metodo(nombre_modelo, X_train, y_train, X_test, y_test, p, c, n_components, k_rango_min, \n",
    "                                               k_rango_max)\n",
    "\n",
    "            ecms = ecms.append({\"particion\": i, \"ECM\": metricas.get(\"ECM\")}, ignore_index=True)            \n",
    "\n",
    "    ecms = ecms.astype({\"particion\":int})\n",
    "    promedio_ecms = ecms[\"ECM\"].mean()\n",
    "    \n",
    "    return promedio_ecms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa8ec1",
   "metadata": {},
   "source": [
    "#### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06260d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_config(configuraciones, nombre_modelo, k_particiones, X, y) :\n",
    "    \n",
    "    '''\n",
    "    Esta función recibe una lista de configuraciones de hiperparámetros y utilizando la función cross validation \n",
    "    obtine el error cuadratico medio para cada configuración y cual es la que genera menor error.\n",
    "    Input:\n",
    "        configuraciones (list): lista exahustiva de diccionarios de posibles valores de configuraciones que incluye\n",
    "        el hiperparametro.\n",
    "        modelo (str): Modelo a utilizar. Las opciones son \"logit\", \"adl\" (análisis discriminante lineal), \"knn\" (vecinos\n",
    "        cercanos) \n",
    "        k_particiones(int): Número entero que indica la cantidad de particiones a utilizar en la validación cruzada\n",
    "        X(df): Muestra de predictores\n",
    "        y(df): Muestra de outcomes\n",
    "        \n",
    "    Output:\n",
    "        optimos (dict): Métricas de interés. Esto es el error cuadratico medio óptimo y la configuracion correspondiente al \n",
    "        menor error cuadratico medio \n",
    "        \n",
    "    '''\n",
    "    ecm_optimo = np.inf\n",
    "    config_optimo = None\n",
    "    for config in configuraciones :\n",
    "        p = config[\"penalty\"]\n",
    "        c = config[\"C\"]\n",
    "        n_components = config[\"n_components\"]\n",
    "        k_rango_min = config[\"k_rango_min\"]\n",
    "        k_rango_max = config[\"k_rango_max\"]\n",
    "        \n",
    "        ecm_promedio = cross_validation(nombre_modelo, k_particiones, X, y, p, c, n_components, k_rango_min, k_rango_max)\n",
    "        if ecm_promedio < ecm_optimo :\n",
    "            ecm_optimo = ecm_promedio \n",
    "            config_optimo = config\n",
    "        \n",
    "    optimos = {\"Error cuadratico medio optimo\":ecm_optimo, \"Configuracion optima\": config_optimo}\n",
    "    return optimos, config_optimo, ecm_optimo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a7718e",
   "metadata": {},
   "source": [
    "#### 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8987e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalua_multiples_metodos(configuraciones, k_particiones, X, y):\n",
    "\n",
    "    '''\n",
    "    Esta función recibe una lista de configuraciones de hiperparámetros y utilizando la función cross validation \n",
    "    obtine el error cuadratico medio para cada configuración y cual es la que genera menor error.\n",
    "    Input:\n",
    "        configuraciones (list): lista exahustiva de diccionarios de posibles valores de configuraciones que incluye el hiperparametro.\n",
    "        k_particiones(int): Número entero que indica la cantidad de particiones a utilizar en la validación cruzada\n",
    "        X(df): Muestra de predictores\n",
    "        y(df): Muestra de outcomes\n",
    "        \n",
    "    Output:\n",
    "        df_modelos (df): Tabla con los diferentes modelos, sus configuraciones y métricas óptimas.\n",
    "        \n",
    "    '''\n",
    "\n",
    "    df_modelos = pd.DataFrame(columns=[\"Modelo\", \"Configuración\", \"Error Cuadratico Medio\", \"Falsos positivos\", \"Falsos negativos\", \"Verdaderos positivos\", \"Verdaderos negativos\", \"Valor AUC\", \"Accuracy score\", \"Precisión\", \"K usados en vecinos cercanos\"])\n",
    "\n",
    "    m = [\"logit\", \"adl\", \"knn\", \"arbol\", \"bagging\", \"random_forest\", \"gradient_boosting\"]\n",
    "    \n",
    "    #Partimos la muestra en dos\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Estandarizamos las observaciones de entrenamiento\n",
    "    X_train_transformed = pd.DataFrame(sc.fit_transform(X_train),index=X_train.index, columns=X_train.columns)\n",
    "\n",
    "    # Estandarizamos las observaciones de test\n",
    "    X_test_transformed = pd.DataFrame(sc.transform(X_test),index=X_test.index, columns=X_test.columns)\n",
    "            \n",
    "    X_TRAIN = X_train_transformed\n",
    "    X_TEST = X_test_transformed\n",
    "    y_TRAIN = y_train\n",
    "    y_TEST = y_test\n",
    "    \n",
    "    for l in m:\n",
    "        nombre_modelo = l\n",
    "        \n",
    "        if l == \"logit\": \n",
    "            optimos, config_optimo, ecm_optimo= evalua_config(configuraciones, \"logit\", k_particiones, X = X_TRAIN, y = y_TRAIN)\n",
    "            p = config_optimo[\"penalty\"]\n",
    "            c = config_optimo[\"C\"]             \n",
    "            \n",
    "            metricas, k_usados, depth_optimo =  evalua_metodo(\"logit\", X_TRAIN, y_TRAIN, X_TEST, y_TEST, p, c, n_components = None, k_rango_max = None, k_rango_min = None)\n",
    "            df_modelos = df_modelos.append({\"Modelo\": \"Regresión Logística\", \"Configuración\": config_optimo, \"Error Cuadratico Medio\": ecm_optimo, \"Falsos positivos\": metricas[\"Falsos positivos\"], \"Falsos negativos\": metricas[\"Falsos negativos\"], \"Verdaderos positivos\": metricas[\"Verdaderos positivos\"], \"Verdaderos negativos\": metricas[\"Verdaderos negativos\"], \"Valor AUC\": metricas[\"Valor AUC\"], \"Accuracy score\": metricas[\"Accuracy score\"], \"Precisión\": metricas[\"Precisión\"], \"K usados en vecinos cercanos\": \" \"}, ignore_index=True)\n",
    "        \n",
    "        elif l ==  \"adl\": \n",
    "            optimos, config_optimo, ecm_optimo= evalua_config(configuraciones, \"adl\", k_particiones, X = X_TRAIN, y = y_TRAIN)\n",
    "            n_components = config_optimo[\"n_components\"]\n",
    "                \n",
    "            metricas, k_usados, depth_optimo = evalua_metodo(\"adl\", X_TRAIN, y_TRAIN, X_TEST, y_TEST, p= None, c= None, n_components = n_components, k_rango_max = None, k_rango_min = None)\n",
    "            \n",
    "            df_modelos = df_modelos.append({\"Modelo\": \"Analisis discriminante lineal\", \"Configuración\": config_optimo, \"Error Cuadratico Medio\": ecm_optimo, \"Falsos positivos\": metricas[\"Falsos positivos\"], \"Falsos negativos\": metricas[\"Falsos negativos\"], \"Verdaderos positivos\": metricas[\"Verdaderos positivos\"], \"Verdaderos negativos\": metricas[\"Verdaderos negativos\"], \"Valor AUC\": metricas[\"Valor AUC\"], \"Accuracy score\": metricas[\"Accuracy score\"], \"Precisión\": metricas[\"Precisión\"], \"K usados en vecinos cercanos\": \" \"}, ignore_index=True)\n",
    "        \n",
    "        elif l == \"knn\":\n",
    "            optimos, config_optimo, ecm_optimo= evalua_config(configuraciones, \"knn\", k_particiones, X = X_TRAIN, y = y_TRAIN)\n",
    "            k_min = config_optimo[\"k_rango_min\"]\n",
    "            k_max = config_optimo[\"k_rango_max\"]\n",
    "            \n",
    "            metricas, k_usados, depth_optimo = evalua_metodo(\"knn\", X_TRAIN, y_TRAIN, X_TEST, y_TEST, p= None, c= None, n_components = None, k_rango_min = k_min, k_rango_max = k_max)\n",
    "            df_modelos = df_modelos.append({\"Modelo\": \"Vecinos cercanos\", \"Configuración\": config_optimo, \"Error Cuadratico Medio\": ecm_optimo, \"Falsos positivos\": metricas[\"Falsos positivos\"], \"Falsos negativos\": metricas[\"Falsos negativos\"], \"Verdaderos positivos\": metricas[\"Verdaderos positivos\"], \"Verdaderos negativos\": metricas[\"Verdaderos negativos\"], \"Valor AUC\": metricas[\"Valor AUC\"], \"Accuracy score\": metricas[\"Accuracy score\"], \"Precisión\": metricas[\"Precisión\"], \"K usados en vecinos cercanos\": k_usados}, ignore_index=True)\n",
    "        \n",
    "        elif l== \"arbol\":\n",
    "            metricas, k_usados, depth_optimo = evalua_metodo(\"arbol\", X_TRAIN, y_TRAIN, X_TEST, y_TEST, p= None, c= None, n_components = None, k_rango_max = None, k_rango_min = None)\n",
    "            df_modelos = df_modelos.append({\"Modelo\": \"Arbol\", \"Configuración\": depth_optimo, \"Error Cuadratico Medio\": ecm_optimo, \"Falsos positivos\": metricas[\"Falsos positivos\"], \"Falsos negativos\": metricas[\"Falsos negativos\"], \"Verdaderos positivos\": metricas[\"Verdaderos positivos\"], \"Verdaderos negativos\": metricas[\"Verdaderos negativos\"], \"Valor AUC\": metricas[\"Valor AUC\"], \"Accuracy score\": metricas[\"Accuracy score\"], \"Precisión\": metricas[\"Precisión\"], \"K usados en vecinos cercanos\": \" \"}, ignore_index=True)\n",
    "        \n",
    "        elif l== \"bagging\":\n",
    "            metricas, k_usados, depth_optimo = evalua_metodo(\"bagging\", X_TRAIN, y_TRAIN, X_TEST, y_TEST, p= None, c= None, n_components = None, k_rango_max = None, k_rango_min = None)\n",
    "            df_modelos = df_modelos.append({\"Modelo\": \"Bagging\", \"Configuración\": \"Predeterminada\", \"Error Cuadratico Medio\": ecm_optimo, \"Falsos positivos\": metricas[\"Falsos positivos\"], \"Falsos negativos\": metricas[\"Falsos negativos\"], \"Verdaderos positivos\": metricas[\"Verdaderos positivos\"], \"Verdaderos negativos\": metricas[\"Verdaderos negativos\"], \"Valor AUC\": metricas[\"Valor AUC\"], \"Accuracy score\": metricas[\"Accuracy score\"], \"Precisión\": metricas[\"Precisión\"], \"K usados en vecinos cercanos\": \" \"}, ignore_index=True)\n",
    "        \n",
    "        elif l== \"radom_forest\":\n",
    "            metricas, k_usados, depth_optimo = evalua_metodo(\"random_forest\", X_TRAIN, y_TRAIN, X_TEST, y_TEST, p= None, c= None, n_components = None, k_rango_max = None, k_rango_min = None)\n",
    "            df_modelos = df_modelos.append({\"Modelo\": \"Random Forest\", \"Configuración\": \"Predeterminada\", \"Error Cuadratico Medio\": ecm_optimo, \"Falsos positivos\": metricas[\"Falsos positivos\"], \"Falsos negativos\": metricas[\"Falsos negativos\"], \"Verdaderos positivos\": metricas[\"Verdaderos positivos\"], \"Verdaderos negativos\": metricas[\"Verdaderos negativos\"], \"Valor AUC\": metricas[\"Valor AUC\"], \"Accuracy score\": metricas[\"Accuracy score\"], \"Precisión\": metricas[\"Precisión\"], \"K usados en vecinos cercanos\": \" \"}, ignore_index=True)\n",
    "        \n",
    "        else:\n",
    "            metricas, k_usados, depth_optimo = evalua_metodo(\"gradient_boosting\", X_TRAIN, y_TRAIN, X_TEST, y_TEST, p= None, c= None, n_components = None, k_rango_max = None, k_rango_min = None)\n",
    "            df_modelos = df_modelos.append({\"Modelo\": \"Gradient Boosting\", \"Configuración\": \"Predeterminada\", \"Error Cuadratico Medio\": ecm_optimo, \"Falsos positivos\": metricas[\"Falsos positivos\"], \"Falsos negativos\": metricas[\"Falsos negativos\"], \"Verdaderos positivos\": metricas[\"Verdaderos positivos\"], \"Verdaderos negativos\": metricas[\"Verdaderos negativos\"], \"Valor AUC\": metricas[\"Valor AUC\"], \"Accuracy score\": metricas[\"Accuracy score\"], \"Precisión\": metricas[\"Precisión\"], \"K usados en vecinos cercanos\": \" \"}, ignore_index=True)\n",
    "    return df_modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee4353a",
   "metadata": {},
   "source": [
    "### Parte III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe0ba60",
   "metadata": {},
   "source": [
    "#### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d9821e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimanamos todas las variables de ingreso que quedaban en el dataframe\n",
    "respondieron.drop(columns= [\"P21\", \"DECOCUR\", \"RDECOCUR\", \"GDECOCUR\", \"ADECOCUR\", \"PONDIIO\", \"TOT_P12\", \"P47T\", \"DECINDR\", \"RDECINDR\", \n",
    "\"GDECINDR\", \"ADECINDR\", \"PONDII\", \"V2_M\", \"V3_M\", \"V4_M\", \"V5_M\", \"V8_M\", \"V9_M\", \"V10_M\", \"V11_M\", \"V12_M\", \"V18_M\", \"V19_AM\", \"V21_M\", \"T_VI\", \"ITF_x\", \"DECIFR_x\",\n",
    "\"RDECIFR_x\", \"GDECIFR_x\", \"ADECIFR_x\", \"IPCF_x\", \"DECCFR_x\", \"RDECCFR_x\", \"GDECCFR_x\", \"ADECCFR_x\", \"PONDIH_x\"], inplace = True)\n",
    "# Eliminamos todas las variables de ingreso del dataframe \n",
    "norespondieron.drop(columns= [\"P21\", \"DECOCUR\", \"RDECOCUR\", \"GDECOCUR\", \"ADECOCUR\", \"PONDIIO\", \"TOT_P12\", \"P47T\", \"DECINDR\", \"RDECINDR\", \n",
    "\"GDECINDR\", \"ADECINDR\", \"PONDII\", \"V2_M\", \"V3_M\", \"V4_M\", \"V5_M\", \"V8_M\", \"V9_M\", \"V10_M\", \"V11_M\", \"V12_M\", \"V18_M\", \"V19_AM\", \"V21_M\", \"T_VI\", \"ITF_x\", \"DECIFR_x\",\n",
    "\"RDECIFR_x\", \"GDECIFR_x\", \"ADECIFR_x\", \"IPCF_x\", \"DECCFR_x\", \"RDECCFR_x\", \"GDECCFR_x\", \"ADECCFR_x\", \"PONDIH_x\"], inplace = True) \n",
    "# Eliminamos las columnas adulto_equiv, ad_equiv_hogar y el id generado anteriormente por nuestra cuenta\n",
    "respondieron.drop(columns=[\"adulto_equiv\", \"ad_equiv_hogar\", \"ingreso_necesario\", \"id\"], inplace=True)\n",
    "norespondieron.drop(columns=[\"adulto_equiv\", \"ad_equiv_hogar\", \"id\"], inplace=True)\n",
    "# Eliminamos la columna de hogar por ser un tipo de id\n",
    "respondieron.drop(columns=[\"hogar\"], inplace=True)\n",
    "respondieron.drop(columns=[\"Edad\"], inplace=True)\n",
    "norespondieron.drop(columns=[\"Edad\"], inplace=True)\n",
    "respondieron.drop(columns=[\"CODUSU\"], inplace=True)\n",
    "norespondieron.drop(columns=[\"CODUSU\"], inplace=True)\n",
    "# Establecemos el vector \"y\" y la matriz \"X\"\n",
    "y = respondieron[\"pobre\"]\n",
    "X = respondieron[respondieron.columns.difference([\"pobre\"])]\n",
    "# Añadimos la constante\n",
    "X[\"cte\"]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785a746",
   "metadata": {},
   "source": [
    "#### 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3aa11380",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuraciones = [{\"penalty\":'l1', \"C\": 1, \"n_components\": 1, \"k_rango_min\": 1, \"k_rango_max\": 5}]\n",
    "# Evaluamos múltiples métodos con la función correspondiente\n",
    "\n",
    "tabla_comparativa = evalua_multiples_metodos(configuraciones, 10, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a076b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuración</th>\n",
       "      <th>Error Cuadratico Medio</th>\n",
       "      <th>Falsos positivos</th>\n",
       "      <th>Falsos negativos</th>\n",
       "      <th>Verdaderos positivos</th>\n",
       "      <th>Verdaderos negativos</th>\n",
       "      <th>Valor AUC</th>\n",
       "      <th>Accuracy score</th>\n",
       "      <th>Precisión</th>\n",
       "      <th>K usados en vecinos cercanos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regresión Logística</td>\n",
       "      <td>{'penalty': 'l1', 'C': 1, 'n_components': 1, '...</td>\n",
       "      <td>0.206717</td>\n",
       "      <td>80</td>\n",
       "      <td>132</td>\n",
       "      <td>220</td>\n",
       "      <td>675</td>\n",
       "      <td>0.7595</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.733333</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analisis discriminante lineal</td>\n",
       "      <td>{'penalty': 'l1', 'C': 1, 'n_components': 1, '...</td>\n",
       "      <td>0.207587</td>\n",
       "      <td>80</td>\n",
       "      <td>137</td>\n",
       "      <td>215</td>\n",
       "      <td>675</td>\n",
       "      <td>0.7524</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.728814</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vecinos cercanos</td>\n",
       "      <td>{'penalty': 'l1', 'C': 1, 'n_components': 1, '...</td>\n",
       "      <td>0.19598</td>\n",
       "      <td>34</td>\n",
       "      <td>170</td>\n",
       "      <td>182</td>\n",
       "      <td>721</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.842593</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arbol</td>\n",
       "      <td>38</td>\n",
       "      <td>0.19598</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>305</td>\n",
       "      <td>706</td>\n",
       "      <td>0.9008</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.861582</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>Predeterminada</td>\n",
       "      <td>0.19598</td>\n",
       "      <td>67</td>\n",
       "      <td>158</td>\n",
       "      <td>194</td>\n",
       "      <td>688</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.743295</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Predeterminada</td>\n",
       "      <td>0.19598</td>\n",
       "      <td>26</td>\n",
       "      <td>105</td>\n",
       "      <td>247</td>\n",
       "      <td>729</td>\n",
       "      <td>0.8336</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.904762</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Predeterminada</td>\n",
       "      <td>0.19598</td>\n",
       "      <td>26</td>\n",
       "      <td>105</td>\n",
       "      <td>247</td>\n",
       "      <td>729</td>\n",
       "      <td>0.8336</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.904762</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Modelo  \\\n",
       "0            Regresión Logística   \n",
       "1  Analisis discriminante lineal   \n",
       "2               Vecinos cercanos   \n",
       "3                          Arbol   \n",
       "4                        Bagging   \n",
       "5              Gradient Boosting   \n",
       "6              Gradient Boosting   \n",
       "\n",
       "                                       Configuración Error Cuadratico Medio  \\\n",
       "0  {'penalty': 'l1', 'C': 1, 'n_components': 1, '...               0.206717   \n",
       "1  {'penalty': 'l1', 'C': 1, 'n_components': 1, '...               0.207587   \n",
       "2  {'penalty': 'l1', 'C': 1, 'n_components': 1, '...                0.19598   \n",
       "3                                                 38                0.19598   \n",
       "4                                     Predeterminada                0.19598   \n",
       "5                                     Predeterminada                0.19598   \n",
       "6                                     Predeterminada                0.19598   \n",
       "\n",
       "  Falsos positivos Falsos negativos Verdaderos positivos Verdaderos negativos  \\\n",
       "0               80              132                  220                  675   \n",
       "1               80              137                  215                  675   \n",
       "2               34              170                  182                  721   \n",
       "3               49               47                  305                  706   \n",
       "4               67              158                  194                  688   \n",
       "5               26              105                  247                  729   \n",
       "6               26              105                  247                  729   \n",
       "\n",
       "  Valor AUC Accuracy score Precisión K usados en vecinos cercanos  \n",
       "0    0.7595           0.81  0.733333                               \n",
       "1    0.7524           0.80  0.728814                               \n",
       "2    0.7360           0.82  0.842593                            4  \n",
       "3    0.9008           0.91  0.861582                               \n",
       "4    0.7312           0.80  0.743295                               \n",
       "5    0.8336           0.88  0.904762                               \n",
       "6    0.8336           0.88  0.904762                               "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos los resultados\n",
    "tabla_comparativa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87d86a",
   "metadata": {},
   "source": [
    "<span style='background :yellow' > Aparece dos veces gradient boosting y no aparece random forest porque en `evalua_multiples_metodos()` escribieron `if l = \"radom_forest\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c062c",
   "metadata": {},
   "source": [
    "#### 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa397fb6",
   "metadata": {},
   "source": [
    "A partir de la medida de Accuracy score y en la mayoría de las medidas de precisión, podemos determinar que el mejor modelo es un Arbol de regresión con una profundidad de 79 nodos. Asimismo, en la problemática en cuestión consideramos necesario poner atención a los \"Falsos negativos\", es decir, aquellas personas que son pobres y se predice como que no lo son dado que esto lo consideramos el error más grave. En este sentido, también observamos que el modelo elegido tiene la menor cantidad de \"Falsos negativos\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aea541",
   "metadata": {},
   "source": [
    "<span style='background :yellow' > El resultado da con una profundidad distanta a la que mencionan, esto es porque varios de estos modelos tienen un componente aleatorio, por lo que para obtener resutlados consistentes tienen que introducirles un argumento `random_state`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4ab5c",
   "metadata": {},
   "source": [
    "#### 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549e95a7",
   "metadata": {},
   "source": [
    "Con respecto a las predicciones del TP3 observamos una mejoría en la capacidad predictiva. En el caso anterior, elegimos regresión logística con un AUC = 0.7608, Accuracy score = 0.81, ECM = 0.198057 y Falsos Negativos = 132. En el caso actual podemos hacer dos comparaciones. Por un lado, si comparamos con el modelo de regresión logística vemos que las predicciones empeoraron levemente porque aumentó el ECM y las medidas de precisión disminuyeron. Por otro lado, si lo comparamos con el modelo óptimo actual vemos que mejoraron las predicciones: AUC = 0.8870, Accuracy Score = 0.90, ECM =  0.19598 y Falsos negativos = 53. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b04b7",
   "metadata": {},
   "source": [
    "<span style='background :yellow' > Al no haber establecido una seed para el componente aleatorio, acá les da todo distinto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a791ae2b",
   "metadata": {},
   "source": [
    "#### 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed18dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "norespondieron[\"cte\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b8742bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)\n",
    "    \n",
    "sc = StandardScaler()\n",
    "\n",
    "# Estandarizamos las observaciones de entrenamiento\n",
    "X_train_transformed = pd.DataFrame(sc.fit_transform(X_train),index=X_train.index, columns=X_train.columns)\n",
    "\n",
    "# Estandarizamos las observaciones de test\n",
    "X_test_transformed = pd.DataFrame(sc.transform(X_test),index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "X_TRAIN = X_train_transformed\n",
    "X_TEST = X_test_transformed\n",
    "y_TRAIN = y_train\n",
    "y_TEST = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af772f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeRegressor(max_depth = 79)      \n",
    "model = decision_tree.fit(X=X_train, y=y_train)\n",
    "        \n",
    "# Realizamos las predicciones para la muestra de testeo\n",
    "pobres_pred_arbol = model.predict(norespondieron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb488b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hogares pobres predichos: 1511.0\n",
      "Hogares que no reportaron ingreso: 1542\n",
      "Proporción de hogares pobres: 97.98962386511025 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Hogares pobres predichos:\", np.sum(pobres_pred_arbol))\n",
    "print(\"Hogares que no reportaron ingreso:\", len(norespondieron))\n",
    "print(\"Proporción de hogares pobres:\", (np.sum(pobres_pred_arbol))/(len(norespondieron))*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c815d4",
   "metadata": {},
   "source": [
    "Vemos que la proporción de hogares pobres obtenida de nuestra predicción con árbol de regresión es del 96.82%. Si bien consideramos que mejora en relación a nuestro trabajo anterior, nos resulta extraño que sea un valor tan alto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
